{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X4TbPhJ5HSm",
        "outputId": "bf96294f-83a3-4d4b-92c4-7ada5f7ead2b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgcKnhgD5ZFB",
        "outputId": "3fcd10f7-3db5-445f-f8db-bd93f00e95c0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.12/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MILESTONE 2 - HATEBR TEXT CLASSIFICATION (Simplified)\n",
        "# Dataset: HateBR[](https://huggingface.co/datasets/franciellevargas/HateBR)\n",
        "# Baselines:\n",
        "#   A) TF-IDF (1-2 n-grams) + linguistic features + LogisticRegression\n",
        "#   B) GloVe Average Embeddings + linguistic features + RandomForestClassifier\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from gensim.models import KeyedVectors\n",
        "import emoji\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "ERckhRDl3zM9"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. CARGA DEL DATASET (como en Proyecto 1)"
      ],
      "metadata": {
        "id": "QTPicA3SBOkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CARGAR DATASET DESDE GITHUB (como en Proyecto 1)\n",
        "# ============================================================\n",
        "\n",
        "# URL \"raw\" del archivo HateBR.csv en GitHub\n",
        "url = \"https://raw.githubusercontent.com/franfgv9/Milestone_1_PLN/refs/heads/main/HateBR.csv\"\n",
        "\n",
        "# Leer el CSV directamente desde GitHub\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Verificar la carga\n",
        "print(\"Dimensiones del dataset:\", df.shape)\n",
        "print(\"Columnas disponibles:\", df.columns.tolist())\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "2qgedN0q67xu",
        "outputId": "8330e6ad-7f89-48c1-bd27-29b8fb4ac6c8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones del dataset: (7000, 8)\n",
            "Columnas disponibles: ['id', 'comentario', 'anotator1', 'anotator2', 'anotator3', 'label_final', 'links_post', 'account_post']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                         comentario  anotator1  \\\n",
              "0   1                                       Mais um lixo          1   \n",
              "1   2                    Essa nao tem vergonha na cara!!          1   \n",
              "2   3                     Essa mulher é doente.pilantra!          1   \n",
              "3   4                                Comunista safada...          1   \n",
              "4   5  Vagabunda. Comunista. Mentirosa. O povo chilen...          1   \n",
              "\n",
              "   anotator2  anotator3  label_final  \\\n",
              "0          1          1            1   \n",
              "1          1          1            1   \n",
              "2          1          1            1   \n",
              "3          1          1            1   \n",
              "4          1          1            1   \n",
              "\n",
              "                                 links_post    account_post  \n",
              "0  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
              "1  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
              "2  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
              "3  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
              "4  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05038c4e-5438-4260-826e-9cb24d24cf12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comentario</th>\n",
              "      <th>anotator1</th>\n",
              "      <th>anotator2</th>\n",
              "      <th>anotator3</th>\n",
              "      <th>label_final</th>\n",
              "      <th>links_post</th>\n",
              "      <th>account_post</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Mais um lixo</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
              "      <td>Carla Zambelli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Essa nao tem vergonha na cara!!</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
              "      <td>Carla Zambelli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Essa mulher é doente.pilantra!</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
              "      <td>Carla Zambelli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Comunista safada...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
              "      <td>Carla Zambelli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Vagabunda. Comunista. Mentirosa. O povo chilen...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
              "      <td>Carla Zambelli</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05038c4e-5438-4260-826e-9cb24d24cf12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-05038c4e-5438-4260-826e-9cb24d24cf12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-05038c4e-5438-4260-826e-9cb24d24cf12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9f2f585c-6c23-4266-8d33-1609271a8d95\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f2f585c-6c23-4266-8d33-1609271a8d95')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9f2f585c-6c23-4266-8d33-1609271a8d95 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2020,\n        \"min\": 1,\n        \"max\": 7000,\n        \"num_unique_values\": 7000,\n        \"samples\": [\n          6501,\n          2945,\n          2025\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comentario\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7000,\n        \"samples\": [\n          \"Lindo de se ver!!! Gente boa, Bolsonaro cuidem das crian\\u00e7as da Ilha do Marajo. Juntos todos podemos. Grata\",\n          \"Me da mais raiva de quem vota nessa corja e apoia esses traidores\",\n          \"ALGU\\u00c9M PODERIA ME INFORMAR SE ESSE COISO \\u00c9 GENTE OU UM DEM\\u00d4NIO ENCORPORADO?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anotator1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anotator2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anotator3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_final\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"links_post\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 78,\n        \"samples\": [\n          \"https://www.instagram.com/reel/C4qyJ4ROSxP/?utm_source=ig_web_copy_link&igsh=MzRlODBiNWFlZA==\",\n          \"https://www.instagram.com/p/B2uThqdH9xI/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"account_post\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Carla Zambelli\",\n          \"Eduardo Bolsonaro\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SELECCIONAR COLUMNAS RELEVANTES\n",
        "# ============================================================\n",
        "\n",
        "df = df[[\"id\", \"comentario\", \"label_final\"]]\n",
        "\n",
        "# Verificar el resultado\n",
        "print(\"\\nColumnas seleccionadas:\", df.columns.tolist())\n",
        "print(\"Dimensiones del dataset:\", df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "PmKG6yvB69_6",
        "outputId": "adf1c350-0a28-43e9-8e45-0d597c9444a1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columnas seleccionadas: ['id', 'comentario', 'label_final']\n",
            "Dimensiones del dataset: (7000, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                         comentario  label_final\n",
              "0   1                                       Mais um lixo            1\n",
              "1   2                    Essa nao tem vergonha na cara!!            1\n",
              "2   3                     Essa mulher é doente.pilantra!            1\n",
              "3   4                                Comunista safada...            1\n",
              "4   5  Vagabunda. Comunista. Mentirosa. O povo chilen...            1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9395e2e2-8cff-4e82-863c-69f8b0bbe759\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comentario</th>\n",
              "      <th>label_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Mais um lixo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Essa nao tem vergonha na cara!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Essa mulher é doente.pilantra!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Comunista safada...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Vagabunda. Comunista. Mentirosa. O povo chilen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9395e2e2-8cff-4e82-863c-69f8b0bbe759')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9395e2e2-8cff-4e82-863c-69f8b0bbe759 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9395e2e2-8cff-4e82-863c-69f8b0bbe759');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0b4e5a33-8554-4d6f-805c-87a16463aaf6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b4e5a33-8554-4d6f-805c-87a16463aaf6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0b4e5a33-8554-4d6f-805c-87a16463aaf6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2020,\n        \"min\": 1,\n        \"max\": 7000,\n        \"num_unique_values\": 7000,\n        \"samples\": [\n          6501,\n          2945,\n          2025\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comentario\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7000,\n        \"samples\": [\n          \"Lindo de se ver!!! Gente boa, Bolsonaro cuidem das crian\\u00e7as da Ilha do Marajo. Juntos todos podemos. Grata\",\n          \"Me da mais raiva de quem vota nessa corja e apoia esses traidores\",\n          \"ALGU\\u00c9M PODERIA ME INFORMAR SE ESSE COISO \\u00c9 GENTE OU UM DEM\\u00d4NIO ENCORPORADO?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_final\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# RENOMBRAR COLUMNAS PARA UNIFORMIDAD\n",
        "# ============================================================\n",
        "\n",
        "df = df.rename(columns={\n",
        "    \"comentario\": \"text\",\n",
        "    \"label_final\": \"label\"\n",
        "})\n",
        "\n",
        "print(\"\\nColumnas finales:\", df.columns.tolist())\n",
        "df.head()\n",
        "\n",
        "print(\"\\nInformación del dataset:\")\n",
        "print(df.info())\n",
        "\n",
        "# Limpiar valores nulos\n",
        "df.dropna(subset=['text', 'label'], inplace=True)\n",
        "df = df[df['label'].isin([0, 1])]  # 0: No ofensivo, 1: Ofensivo\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(f\"\\nDataset final: {len(df)} ejemplos\")\n",
        "print(\"Distribución de clases:\")\n",
        "print(df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIShmgJE6-6w",
        "outputId": "7c0912fe-2e93-42d2-fda2-28b4a1c35edc"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columnas finales: ['id', 'text', 'label']\n",
            "\n",
            "Información del dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7000 entries, 0 to 6999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      7000 non-null   int64 \n",
            " 1   text    7000 non-null   object\n",
            " 2   label   7000 non-null   int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 164.2+ KB\n",
            "None\n",
            "\n",
            "Dataset final: 7000 ejemplos\n",
            "Distribución de clases:\n",
            "label\n",
            "1    3500\n",
            "0    3500\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. LIMPIEZA GENERAL (para features lingüísticas)"
      ],
      "metadata": {
        "id": "i7DslKCOBQ9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La idea es:\n",
        "\n",
        "Limpiar ligeramente el texto, pero sin “destrozarlo”, para poder extraer después features lingüísticas (POS tags, entidades, dependencias, etc.).\n",
        "\n",
        "Guardar esa versión limpia en una nueva columna del DataFrame.\n",
        "\n",
        "Descargar y cargar spaCy en portugués, que usarás más tarde para sacar esas features."
      ],
      "metadata": {
        "id": "9iyfOnDOcVMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PREPROCESAMIENTO GENERAL (para features lingüísticas)\n",
        "# ============================================================\n",
        "\n",
        "def clean_for_features(text):\n",
        "    text = re.sub(r'http[s]?://\\S+', '', text)  # Quitar URLs\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()    # Normalizar espacios\n",
        "    return text\n",
        "\n",
        "df['text_features'] = df['text'].apply(clean_for_features)\n",
        "\n",
        "# Descargar modelo spaCy para portugués si no está instalado\n",
        "!python -m spacy download pt_core_news_sm\n",
        "\n",
        "# Cargar modelo spaCy para portugués\n",
        "print(\"\\nCargando modelo spaCy (pt_core_news_sm)...\")\n",
        "nlp = spacy.load(\"pt_core_news_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amjW7B2D7B8K",
        "outputId": "5d6625b4-10f2-4d85-f7d3-a191d185cfb9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "Cargando modelo spaCy (pt_core_news_sm)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por qué no más limpieza?\n",
        "→ Porque queremos preservar mayúsculas, signos, emojis para extraer features.\n",
        "Solo quitamos URLs y espacios extra → no afectan al análisis lingüístico."
      ],
      "metadata": {
        "id": "LMqedASdBG74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí usas expresiones regulares con re.sub para eliminar enlaces.\n",
        "\n",
        "re.sub(patrón, reemplazo, texto)\n",
        "→ busca el patrón en texto y lo sustituye por reemplazo.\n",
        "\n",
        "Desglose del patrón r'http[s]?://\\S+':\n",
        "\n",
        "r'': raw string → para que Python no interprete \\ como escapes raros.\n",
        "\n",
        "'http': busca exactamente la secuencia de letras http.\n",
        "\n",
        "'[s]?':\n",
        "\n",
        "[s] significa la letra s.\n",
        "\n",
        "? significa “0 o 1 vez”.\n",
        "\n",
        "Es decir, coincide con http:// y también con https://.\n",
        "\n",
        "'://': los caracteres :// literalmente.\n",
        "\n",
        "\\S+:\n",
        "\n",
        "\\S = “cualquier carácter que no sea espacio en blanco”.\n",
        "\n",
        "+ = “1 o más veces”."
      ],
      "metadata": {
        "id": "NQym42fRc2Vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patrón r'\\s+':\n",
        "\n",
        "\\s = cualquier espacio en blanco (espacio, tabulación, salto de línea, etc.).\n",
        "\n",
        "+ = uno o más seguidos.\n",
        "\n",
        "Es decir, detecta “bloques de espacios en blanco”.\n",
        "\n",
        "re.sub(r'\\s+', ' ', text):\n",
        "\n",
        "Sustituye cualquier bloque de espacios/blancos (por ejemplo, \" \", \"\\n\\n\", \"\\t \\n\") por un único espacio \" \".\n",
        "\n",
        "Esto “normaliza” la separación entre palabras.\n",
        "\n",
        ".strip():\n",
        "\n",
        "Elimina espacios al principio y al final del string.\n",
        "\n",
        "Así no quedan frases empezando o terminando con espacios.\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "Antes: \" Olha isso: ridículo \\n\\n \"\n",
        "\n",
        "Después: \"Olha isso: ridículo\""
      ],
      "metadata": {
        "id": "fs94_aaedjKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. LIMPIEZA ESPECÍFICA POR MODELO"
      ],
      "metadata": {
        "id": "LjyLt8FkvqUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# LIMPIEZA ESPECÍFICA POR MODELO\n",
        "# ============================================================\n",
        "\n",
        "# --- Modelo A: TF-IDF (superficial) ---\n",
        "def clean_for_tfidf(text):\n",
        "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['text_clean_tfidf'] = df['text'].apply(clean_for_tfidf)\n",
        "\n",
        "# No se baja a minúsculas → lowercase=False en TfidfVectorizer\n",
        "# Se preservan mayúsculas → \"IDIOTA\" ≠ \"idiota\" → señal de ofensa\n",
        "\n",
        "# --- Modelo B: Embeddings (semántico) ---\n",
        "emoji_map = {'[laughing face]': 'risada', '[angry face]': 'raiva', '[heart]': 'amor'}\n",
        "\n",
        "def replace_emojis(text):\n",
        "    for emj, word in emoji_map.items():\n",
        "        text = text.replace(emj, f' {word} ')\n",
        "    return text\n",
        "\n",
        "def clean_for_embeddings(text):\n",
        "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
        "    text = replace_emojis(text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-záéíóúâêôãõç\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Baja a minúsculas → GloVe es case-sensitive\n",
        "# Reemplaza emojis → \"risada\" en lugar de cara riendo\n",
        "# Solo letras y acentos → compatibilidad con GloVe\n",
        "\n",
        "df['text_clean_emb'] = df['text'].apply(clean_for_embeddings)"
      ],
      "metadata": {
        "id": "pBp0ItnAvlGe"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. EXTRACCIÓN DE FEATURES LINGÜÍSTICAS"
      ],
      "metadata": {
        "id": "oTVHodg3BUlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "portuguese_stopwords = stopwords.words('portuguese')\n",
        "\n",
        "print(f\"Loaded {len(portuguese_stopwords)} Portuguese stopwords.\")\n",
        "print(\"First 10 stopwords:\", portuguese_stopwords[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_kLSpc0tHq_",
        "outputId": "e436d48d-f3a0-427f-dba9-650863105c7a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 207 Portuguese stopwords.\n",
            "First 10 stopwords: ['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "offensive_comments = df[df['label'] == 1]['text_clean_emb']\n",
        "inoffensive_comments = df[df['label'] == 0]['text_clean_emb']\n",
        "\n",
        "# Tokenize the comments\n",
        "all_offensive_tokens = [word for comment in offensive_comments for word in comment.split()]\n",
        "all_inoffensive_tokens = [word for comment in inoffensive_comments for word in comment.split()]\n",
        "\n",
        "print(f\"Total offensive tokens: {len(all_offensive_tokens)}\")\n",
        "print(f\"Total inoffensive tokens: {len(all_inoffensive_tokens)}\")\n",
        "\n",
        "filtered_offensive_tokens = [word for word in all_offensive_tokens if word not in portuguese_stopwords]\n",
        "filtered_inoffensive_tokens = [word for word in all_inoffensive_tokens if word not in portuguese_stopwords]\n",
        "\n",
        "print(f\"Total offensive tokens after stopword removal: {len(filtered_offensive_tokens)}\")\n",
        "print(f\"Total inoffensive tokens after stopword removal: {len(filtered_inoffensive_tokens)}\")\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "offensive_word_counts = Counter(filtered_offensive_tokens)\n",
        "inoffensive_word_counts = Counter(filtered_inoffensive_tokens)\n",
        "\n",
        "print(\"Top 10 most common offensive words (after stopword removal):\")\n",
        "print(offensive_word_counts.most_common(10))\n",
        "print(\"\\nTop 10 most common inoffensive words (after stopword removal):\")\n",
        "print(inoffensive_word_counts.most_common(10))\n",
        "\n",
        "unique_offensive_tokens_scored = {}\n",
        "\n",
        "# Consider words present in offensive comments\n",
        "for word, offensive_count in offensive_word_counts.items():\n",
        "    inoffensive_count = inoffensive_word_counts.get(word, 0)\n",
        "\n",
        "    # Calculate a score: higher if much more frequent in offensive comments\n",
        "    # Add 1 to avoid division by zero if inoffensive_count is 0\n",
        "    # and to smooth the ratio a bit. Higher 'offensive_count' is also weighted\n",
        "    score = offensive_count / (inoffensive_count + 1) * offensive_count\n",
        "\n",
        "    # Only consider words that are frequent enough in offensive comments (e.g., > 10 occurrences)\n",
        "    # and have a significant score\n",
        "    if offensive_count > 10 and score > 50:\n",
        "        unique_offensive_tokens_scored[word] = score\n",
        "\n",
        "# Sort and display top unique offensive tokens\n",
        "sorted_unique_offensive_tokens = sorted(unique_offensive_tokens_scored.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "print(\"\\nTop 20 Unique Offensive Tokens (highly frequent in offensive, rare in inoffensive):\")\n",
        "for word, score in sorted_unique_offensive_tokens[:20]:\n",
        "    print(f\"- {word} (Offensive Count: {offensive_word_counts[word]}, Inoffensive Count: {inoffensive_word_counts.get(word, 0)}, Score: {score:.2f})\")\n",
        "\n",
        "unique_offensive_words = set(item[0] for item in sorted_unique_offensive_tokens)\n",
        "print(f\"Extracted {len(unique_offensive_words)} unique offensive words.\")\n",
        "print(f\"First 10 unique offensive words: {list(unique_offensive_words)[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7GU9A-GtIeZ",
        "outputId": "21546efb-264d-4948-a05b-683ba8ba9eeb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total offensive tokens: 53047\n",
            "Total inoffensive tokens: 42523\n",
            "Total offensive tokens after stopword removal: 31254\n",
            "Total inoffensive tokens after stopword removal: 25031\n",
            "Top 10 most common offensive words (after stopword removal):\n",
            "[('pra', 357), ('vai', 270), ('brasil', 235), ('cara', 188), ('vc', 178), ('presidente', 163), ('povo', 156), ('vergonha', 155), ('esquerda', 144), ('tá', 138)]\n",
            "\n",
            "Top 10 most common inoffensive words (after stopword removal):\n",
            "[('presidente', 358), ('parabéns', 334), ('deus', 290), ('brasil', 266), ('vc', 175), ('pra', 171), ('bolsonaro', 167), ('sempre', 137), ('bem', 134), ('lula', 124)]\n",
            "\n",
            "Top 20 Unique Offensive Tokens (highly frequent in offensive, rare in inoffensive):\n",
            "- merda (Offensive Count: 104, Inoffensive Count: 0, Score: 10816.00)\n",
            "- pirralha (Offensive Count: 134, Inoffensive Count: 1, Score: 8978.00)\n",
            "- cadeia (Offensive Count: 91, Inoffensive Count: 0, Score: 8281.00)\n",
            "- lixo (Offensive Count: 135, Inoffensive Count: 2, Score: 6075.00)\n",
            "- nojo (Offensive Count: 74, Inoffensive Count: 0, Score: 5476.00)\n",
            "- vergonha (Offensive Count: 155, Inoffensive Count: 4, Score: 4805.00)\n",
            "- globolixo (Offensive Count: 61, Inoffensive Count: 0, Score: 3721.00)\n",
            "- bandido (Offensive Count: 78, Inoffensive Count: 1, Score: 3042.00)\n",
            "- idiota (Offensive Count: 55, Inoffensive Count: 0, Score: 3025.00)\n",
            "- nojento (Offensive Count: 49, Inoffensive Count: 0, Score: 2401.00)\n",
            "- velho (Offensive Count: 47, Inoffensive Count: 0, Score: 2209.00)\n",
            "- bosta (Offensive Count: 44, Inoffensive Count: 0, Score: 1936.00)\n",
            "- verme (Offensive Count: 44, Inoffensive Count: 0, Score: 1936.00)\n",
            "- vagabundo (Offensive Count: 42, Inoffensive Count: 0, Score: 1764.00)\n",
            "- ridículo (Offensive Count: 39, Inoffensive Count: 0, Score: 1521.00)\n",
            "- comunista (Offensive Count: 38, Inoffensive Count: 0, Score: 1444.00)\n",
            "- bando (Offensive Count: 38, Inoffensive Count: 0, Score: 1444.00)\n",
            "- imbecil (Offensive Count: 37, Inoffensive Count: 0, Score: 1369.00)\n",
            "- canalha (Offensive Count: 51, Inoffensive Count: 1, Score: 1300.50)\n",
            "- podre (Offensive Count: 35, Inoffensive Count: 0, Score: 1225.00)\n",
            "Extracted 257 unique offensive words.\n",
            "First 10 unique offensive words: ['bozo', 'traidora', 'absurdo', 'cansa', 'alguma', 'pra', 'manda', 'gado', 'falso', 'cara']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_linguistic_features(text):\n",
        "    doc = nlp(text)\n",
        "    features = {}\n",
        "\n",
        "    # Básicas\n",
        "    features['n_tokens'] = len(doc)\n",
        "    features['upper_ratio'] = sum(1 for c in text if c.isupper()) / len(text) if text else 0\n",
        "    features['n_exclam'] = text.count('!')\n",
        "    features['n_question'] = text.count('?')\n",
        "\n",
        "    # POS tags (solo adjetivos, sustantivos, verbos)  -> Son categorías especialmente relacionadas con lenguaje ofensivo\n",
        "    pos_counts = {'ADJ': 0, 'NOUN': 0, 'VERB': 0}\n",
        "    for token in doc:\n",
        "        if token.pos_ in pos_counts:\n",
        "            pos_counts[token.pos_] += 1         # si coincide la categoría gramatical con las que tenemos en pos_counts entonces sumas 1\n",
        "    total = sum(pos_counts.values())\n",
        "    for pos in pos_counts:\n",
        "        features[f'prop_{pos.lower()}'] = pos_counts[pos] / total if total > 0 else 0\n",
        "\n",
        "    # Emojis\n",
        "    features['n_emojis'] = len(emoji.emoji_list(text))\n",
        "\n",
        "    # Nuevas Features Solicitadas:\n",
        "    # 1. Presencia de hashtags\n",
        "    features['n_hashtags'] = len(re.findall(r'#\\w+', text))\n",
        "\n",
        "    # 2. Presencia de menciones (@usuario)\n",
        "    features['n_mentions'] = len(re.findall(r'@\\w+', text))\n",
        "\n",
        "    # 3. Presencia de pronombres de segunda persona\n",
        "    n_second_person_pronouns = 0\n",
        "    for token in doc:\n",
        "        # Check if it's a pronoun and has 'Person=2' morphology\n",
        "        if token.pos_ == \"PRON\" and token.morph.get(\"Person\") == [\"2\"]:\n",
        "            n_second_person_pronouns += 1\n",
        "    features['n_second_person_pronouns'] = n_second_person_pronouns\n",
        "\n",
        "    # 4. Presencia del patrón NOUN + ADJ\n",
        "    n_noun_adj_pattern = 0\n",
        "    for i, token in enumerate(doc):\n",
        "        if token.pos_ == \"NOUN\" and i + 1 < len(doc) and doc[i + 1].pos_ == \"ADJ\":\n",
        "            n_noun_adj_pattern += 1\n",
        "    features['n_noun_adj_pattern'] = n_noun_adj_pattern\n",
        "\n",
        "    # 5. Presencia del patrón pronombre 2ª persona + adjetivo\n",
        "    n_pron_2nd_adj_pattern = 0\n",
        "    for i, token in enumerate(doc):\n",
        "        if token.pos_ == \"PRON\" and token.morph.get(\"Person\") == [\"2\"] and i + 1 < len(doc) and doc[i + 1].pos_ == \"ADJ\":\n",
        "            n_pron_2nd_adj_pattern += 1\n",
        "    features['n_pron_2nd_adj_pattern'] = n_pron_2nd_adj_pattern\n",
        "\n",
        "    # New Feature: Count of unique offensive tokens\n",
        "    n_unique_offensive_tokens = 0\n",
        "    for token in doc:\n",
        "        if token.lemma_.lower() in unique_offensive_words:\n",
        "            n_unique_offensive_tokens += 1\n",
        "    features['n_unique_offensive_tokens'] = n_unique_offensive_tokens\n",
        "\n",
        "\n",
        "    return features\n",
        "\n",
        "print(\"Extrayendo features lingüísticas...\")\n",
        "feat_list = df['text_features'].apply(extract_linguistic_features)\n",
        "feat_df = pd.DataFrame(feat_list.tolist())\n",
        "print(f\"Features extraídas: {feat_df.shape[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVPMNyNy7E6a",
        "outputId": "984cad0d-a530-4859-a7a0-d7ee13a97b24"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extrayendo features lingüísticas...\n",
            "Features extraídas: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(feat_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5mdtAUL84ru",
        "outputId": "222fb427-1c00-453a-8c27-61007518b7e8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   n_tokens  upper_ratio  n_exclam  n_question  prop_adj  prop_noun  \\\n",
            "0         3     0.083333         0           0      0.00       1.00   \n",
            "1         8     0.032258         2           0      0.00       0.75   \n",
            "2         5     0.033333         1           0      0.00       1.00   \n",
            "3         3     0.052632         0           0      0.00       0.50   \n",
            "4        15     0.051282         0           0      0.25       0.50   \n",
            "\n",
            "   prop_verb  n_emojis  n_hashtags  n_mentions  n_second_person_pronouns  \\\n",
            "0       0.00         0           0           0                         0   \n",
            "1       0.25         0           0           0                         0   \n",
            "2       0.00         0           0           0                         0   \n",
            "3       0.50         0           0           0                         0   \n",
            "4       0.25         0           0           0                         0   \n",
            "\n",
            "   n_noun_adj_pattern  n_pron_2nd_adj_pattern  n_unique_offensive_tokens  \n",
            "0                   0                       0                          1  \n",
            "1                   0                       0                          4  \n",
            "2                   0                       0                          1  \n",
            "3                   0                       0                          1  \n",
            "4                   1                       0                          6  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['text'].head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGTnfaHUhIbB",
        "outputId": "b2fdb353-fc33-4cc6-a62e-425b06253a24"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                         Mais um lixo\n",
            "1                      Essa nao tem vergonha na cara!!\n",
            "2                       Essa mulher é doente.pilantra!\n",
            "3                                  Comunista safada...\n",
            "4    Vagabunda. Comunista. Mentirosa. O povo chilen...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n_tokens    Comentarios largos → más contexto\n",
        "# upper_ratio   MAYÚSCULAS = agresividad\n",
        "# n_exclam, n_question    Exclamaciones = emoción fuerte\n",
        "# prop_adj, prop_noun, prop_verb    Insultos suelen tener más adjetivos (\"feio\" \"idiota\")   --> IMPORTANTE: Estas proporciones no son respecto al total de tokens, sino respecto al total de ADJ + NOUN + VERB --> Por eso siempre suman 1\n",
        "# n_emojis       Emojis como risa o cara enojada refuerzan el tono"
      ],
      "metadata": {
        "id": "FZbEoEkkCTcr"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. DIVISIÓN DE DATOS"
      ],
      "metadata": {
        "id": "jUId6HrrCmg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# DIVISIÓN DE DATOS\n",
        "# ============================================================\n",
        "\n",
        "X_text_tfidf = df['text_clean_tfidf']\n",
        "X_text_emb = df['text_clean_emb']\n",
        "X_features = feat_df.values\n",
        "y = df['label'].values\n",
        "\n",
        "# 1. Separar 30% temporal (val + test)\n",
        "X_train_tfidf, X_temp_tfidf, \\\n",
        "X_train_emb, X_temp_emb, \\\n",
        "X_feat_train, X_temp_feat, \\\n",
        "y_train, y_temp = train_test_split(\n",
        "    X_text_tfidf, X_text_emb, X_features, y,\n",
        "    test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 2. Del 30% temporal → 15% val + 15% test\n",
        "X_val_tfidf, X_test_tfidf, \\\n",
        "X_val_emb, X_test_emb, \\\n",
        "X_val_feat, X_feat_test, \\\n",
        "y_val, y_test = train_test_split(\n",
        "    X_temp_tfidf, X_temp_emb, X_temp_feat, y_temp,\n",
        "    test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Escalar solo con train\n",
        "scaler = StandardScaler()\n",
        "X_feat_train_scaled = scaler.fit_transform(X_feat_train)\n",
        "X_val_feat_scaled = scaler.transform(X_val_feat)\n",
        "X_feat_test_scaled = scaler.transform(X_feat_test)\n",
        "\n",
        "# Escalado: necesario para combinar con TF-IDF y embeddings\n"
      ],
      "metadata": {
        "id": "cYEgEZQm7MGg"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. MODELO A: TF-IDF + FEATURES + LogisticRegression"
      ],
      "metadata": {
        "id": "nF-z6xn3DAAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# ============================================================\n",
        "# MODELO A: TF-IDF + FEATURES → 3 ALGORITMOS + GRIDSEARCH\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING MODEL A: TF-IDF (1-2 n-grams) + LINGUISTIC FEATURES\")\n",
        "print(\"GridSearchCV con cv=3 → SOLO sobre TRAIN\")\n",
        "print(\"Validation set NO se usa en tuning → queda para análisis posterior si quieres\")\n",
        "print(\"Evaluación FINAL: solo en TEST (15%)\")\n",
        "print(\"=\"*70)\n",
        "# Vectorizador TF-IDF\n",
        "tfidf = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    lowercase=False,\n",
        "    max_features=10000\n",
        ")\n",
        "\n",
        "X_tfidf_train = tfidf.fit_transform(X_train_tfidf)\n",
        "X_tfidf_val   = tfidf.transform(X_val_tfidf)\n",
        "X_tfidf_test  = tfidf.transform(X_test_tfidf)\n",
        "\n",
        "# Combinar con features lingüísticas\n",
        "X_train_A = hstack([X_tfidf_train, csr_matrix(X_feat_train_scaled)])\n",
        "X_val_A   = hstack([X_tfidf_val,   csr_matrix(X_val_feat_scaled)])\n",
        "X_test_A  = hstack([X_tfidf_test,  csr_matrix(X_feat_test_scaled)])\n",
        "\n",
        "print(f\"TF-IDF vocabulary size: {len(tfidf.vocabulary_):,} terms\")\n",
        "print(f\"Train shape: {X_train_A.shape} | Val shape: {X_val_A.shape} | Test shape: {X_test_A.shape}\")\n",
        "\n",
        "# Resultados\n",
        "results_A = {}\n",
        "\n",
        "# 1. Logistic Regression\n",
        "print(\"\\nTraining Logistic Regression (GridSearch on C)...\")\n",
        "log_grid_A = GridSearchCV( # Renamed\n",
        "    LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
        "    param_grid={'C': [0.1, 1.0, 10.0]},\n",
        "    cv=3,                    # ← 3-fold CROSS-VALIDATION solo en TRAIN\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "log_grid_A.fit(X_train_A, y_train)\n",
        "y_pred_log = log_grid_A.predict(X_test_A)\n",
        "f1_log = f1_score(y_test, y_pred_log, average='macro')\n",
        "results_A['LogisticRegression'] = (f1_log, log_grid_A.best_params_)\n",
        "print(f\"   Best C: {log_grid_A.best_params_['C']} | F1-macro (TEST): {f1_log:.4f}\")\n",
        "\n",
        "# 2. Random Forest\n",
        "print(\"Training Random Forest...\")\n",
        "rf_grid_A = GridSearchCV( # Renamed\n",
        "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "    param_grid={\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [None, 20, 30]\n",
        "    },\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_grid_A.fit(X_train_A, y_train)\n",
        "y_pred_rf = rf_grid_A.predict(X_test_A)\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average='macro')\n",
        "results_A['RandomForest'] = (f1_rf, rf_grid_A.best_params_)\n",
        "print(f\"   Best params: {rf_grid_A.best_params_} | F1-macro (TEST): {f1_rf:.4f}\")\n",
        "\n",
        "# 3. Linear SVM\n",
        "print(\"Training Linear SVM...\")\n",
        "svm_grid_A = GridSearchCV( # Renamed\n",
        "    LinearSVC(class_weight='balanced', max_iter=10000, random_state=42),\n",
        "    param_grid={'C': [0.01, 0.1, 1.0, 10.0]},\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "svm_grid_A.fit(X_train_A, y_train)\n",
        "y_pred_svm = svm_grid_A.predict(X_test_A)\n",
        "f1_svm = f1_score(y_test, y_pred_svm, average='macro')\n",
        "results_A['SVM'] = (f1_svm, svm_grid_A.best_params_)\n",
        "print(f\"   Best C: {svm_grid_A.best_params_['C']} | F1-macro (TEST): {f1_svm:.4f}\")\n",
        "\n",
        "# RESUMEN\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL A SUMMARY (TF-IDF + Linguistic Features)\")\n",
        "print(\"Tuning: cv=3 sobre TRAIN | Evaluación: TEST (15%)\")\n",
        "print(\"=\"*60)\n",
        "for name, (f1, params) in results_A.items():\n",
        "    print(f\"{name:18} → F1-macro (TEST): {f1:.4f} | Best params: {params}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "best_A_name = max(results_A, key=lambda k: results_A[k][0])\n",
        "best_A_f1 = results_A[best_A_name][0]\n",
        "print(f\"WINNER MODEL A → {best_A_name}\")\n",
        "print(f\"F1-macro final en TEST: {best_A_f1:.4f}\")\n",
        "print(\"Validation set reservado para futuros experimentos o ensemble\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdsY1GRR7S3_",
        "outputId": "74e0815b-0939-495a-d4ce-b1fb79f7988f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING MODEL A: TF-IDF (1-2 n-grams) + LINGUISTIC FEATURES\n",
            "GridSearchCV con cv=3 → SOLO sobre TRAIN\n",
            "Validation set NO se usa en tuning → queda para análisis posterior si quieres\n",
            "Evaluación FINAL: solo en TEST (15%)\n",
            "======================================================================\n",
            "TF-IDF vocabulary size: 10,000 terms\n",
            "Train shape: (4900, 10014) | Val shape: (1050, 10014) | Test shape: (1050, 10014)\n",
            "\n",
            "Training Logistic Regression (GridSearch on C)...\n",
            "   Best C: 10.0 | F1-macro (TEST): 0.8092\n",
            "Training Random Forest...\n",
            "   Best params: {'max_depth': None, 'n_estimators': 200} | F1-macro (TEST): 0.7590\n",
            "Training Linear SVM...\n",
            "   Best C: 1.0 | F1-macro (TEST): 0.8063\n",
            "\n",
            "============================================================\n",
            "MODEL A SUMMARY (TF-IDF + Linguistic Features)\n",
            "Tuning: cv=3 sobre TRAIN | Evaluación: TEST (15%)\n",
            "============================================================\n",
            "LogisticRegression → F1-macro (TEST): 0.8092 | Best params: {'C': 10.0}\n",
            "RandomForest       → F1-macro (TEST): 0.7590 | Best params: {'max_depth': None, 'n_estimators': 200}\n",
            "SVM                → F1-macro (TEST): 0.8063 | Best params: {'C': 1.0}\n",
            "============================================================\n",
            "WINNER MODEL A → LogisticRegression\n",
            "F1-macro final en TEST: 0.8092\n",
            "Validation set reservado para futuros experimentos o ensemble\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. MODELO B: GloVe + FEATURES + RandomForest"
      ],
      "metadata": {
        "id": "upWl8S-rDbb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_kme5xdd3ci",
        "outputId": "d561a0e5-ae66-426c-da70-dd6e583a7f67"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# MODELO B: GLOVE EMBEDDINGS + FEATURES (gensim)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ENTRENANDO MODELO B: GLOVE + FEATURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Cargar GloVe (descargar desde NILC: http://nilc.icmc.usp.br/nwp/embeddings)\n",
        "# Ejemplo: glove_s100.txt\n",
        "glove_path = \"/content/drive/MyDrive/proyecto2_PLN/glove_s100.txt\"\n",
        "print(f\"Cargando GloVe desde: {glove_path}\")\n",
        "w2v_model = KeyedVectors.load_word2vec_format(glove_path)\n",
        "\n",
        "def get_avg_embedding(text, model):\n",
        "    words = text.split()\n",
        "    valid = [w for w in words if w in model]\n",
        "    if not valid:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean([model[w] for w in valid], axis=0)\n",
        "\n",
        "# Representación de frase: promedio de vectores\n",
        "# Palabras fuera del vocabulario: ignoradas\n",
        "\n",
        "print(\"Calculando embeddings promedio para train, val y test...\")\n",
        "X_emb_train = np.array([get_avg_embedding(t, w2v_model) for t in X_train_emb])\n",
        "X_emb_val   = np.array([get_avg_embedding(t, w2v_model) for t in X_val_emb])\n",
        "X_emb_test  = np.array([get_avg_embedding(t, w2v_model) for t in X_test_emb])\n",
        "\n",
        "#Combinar con features lingüísticas escaladas\n",
        "X_train_B = np.hstack([X_emb_train, X_feat_train_scaled])\n",
        "X_val_B   = np.hstack([X_emb_val,   X_val_feat_scaled])\n",
        "X_test_B  = np.hstack([X_emb_test,  X_feat_test_scaled])\n",
        "\n",
        "print(f\"GloVe embedding dimension: {X_emb_train.shape[1]}\")\n",
        "print(f\"Train shape: {X_train_B.shape} | Val shape: {X_val_B.shape} | Test shape: {X_test_B.shape}\")\n",
        "# Resultados\n",
        "results_B = {}\n",
        "\n",
        "# 1. Logistic Regression\n",
        "print(\"\\nTraining Logistic Regression (GridSearch on C)...\")\n",
        "log_grid_B = GridSearchCV( # Renamed\n",
        "    LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
        "    param_grid={'C': [0.1, 1.0, 10.0]},\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "log_grid_B.fit(X_train_B, y_train)\n",
        "y_pred_log = log_grid_B.predict(X_test_B)\n",
        "f1_log = f1_score(y_test, y_pred_log, average='macro')\n",
        "results_B['LogisticRegression'] = (f1_log, log_grid_B.best_params_)\n",
        "print(f\"   Best C: {log_grid_B.best_params_['C']} | F1-macro (TEST): {f1_log:.4f}\")\n",
        "\n",
        "# 2. Random Forest\n",
        "print(\"Training Random Forest...\")\n",
        "rf_grid_B = GridSearchCV( # Renamed\n",
        "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "    param_grid={\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [None, 20, 30]\n",
        "    },\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_grid_B.fit(X_train_B, y_train)\n",
        "y_pred_rf = rf_grid_B.predict(X_test_B)\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average='macro')\n",
        "results_B['RandomForest'] = (f1_rf, rf_grid_B.best_params_)\n",
        "print(f\"   Best params: {rf_grid_B.best_params_} | F1-macro (TEST): {f1_rf:.4f}\")\n",
        "\n",
        "# 3. Linear SVM\n",
        "print(\"Training Linear SVM...\")\n",
        "svm_grid_B = GridSearchCV( # Renamed\n",
        "    LinearSVC(class_weight='balanced', max_iter=10000, random_state=42),\n",
        "    param_grid={'C': [0.01, 0.1, 1.0, 10.0]},\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "svm_grid_B.fit(X_train_B, y_train)\n",
        "y_pred_svm = svm_grid_B.predict(X_test_B)\n",
        "f1_svm = f1_score(y_test, y_pred_svm, average='macro')\n",
        "results_B['SVM'] = (f1_svm, svm_grid_B.best_params_)\n",
        "print(f\"   Best C: {svm_grid_B.best_params_['C']} | F1-macro (TEST): {f1_svm:.4f}\")\n",
        "\n",
        "# RESUMEN FINAL MODELO B\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL B SUMMARY (GloVe avg + Linguistic Features)\")\n",
        "print(\"Tuning: cv=3 sobre TRAIN | Evaluación: TEST (15%)\")\n",
        "print(\"=\"*60)\n",
        "for name, (f1, params) in results_B.items():\n",
        "    print(f\"{name:18} → F1-macro (TEST): {f1:.4f} | Best params: {params}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "best_B_name = max(results_B, key=lambda k: results_B[k][0])\n",
        "best_B_f1 = results_B[best_B_name][0]\n",
        "print(f\"WINNER MODEL B → {best_B_name}\")\n",
        "print(f\"F1-macro final en TEST: {best_B_f1:.4f}\")\n",
        "print(\"Validation set reservado para futuros análisis o ensemble\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWXbU7Mz7XIv",
        "outputId": "4c78d83f-1843-42ae-bad1-b2614391103f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ENTRENANDO MODELO B: GLOVE + FEATURES\n",
            "============================================================\n",
            "Cargando GloVe desde: /content/drive/MyDrive/proyecto2_PLN/glove_s100.txt\n",
            "Calculando embeddings promedio para train, val y test...\n",
            "GloVe embedding dimension: 100\n",
            "Train shape: (4900, 114) | Val shape: (1050, 114) | Test shape: (1050, 114)\n",
            "\n",
            "Training Logistic Regression (GridSearch on C)...\n",
            "   Best C: 1.0 | F1-macro (TEST): 0.8248\n",
            "Training Random Forest...\n",
            "   Best params: {'max_depth': None, 'n_estimators': 300} | F1-macro (TEST): 0.8009\n",
            "Training Linear SVM...\n",
            "   Best C: 0.1 | F1-macro (TEST): 0.8248\n",
            "\n",
            "============================================================\n",
            "MODEL B SUMMARY (GloVe avg + Linguistic Features)\n",
            "Tuning: cv=3 sobre TRAIN | Evaluación: TEST (15%)\n",
            "============================================================\n",
            "LogisticRegression → F1-macro (TEST): 0.8248 | Best params: {'C': 1.0}\n",
            "RandomForest       → F1-macro (TEST): 0.8009 | Best params: {'max_depth': None, 'n_estimators': 300}\n",
            "SVM                → F1-macro (TEST): 0.8248 | Best params: {'C': 0.1}\n",
            "============================================================\n",
            "WINNER MODEL B → LogisticRegression\n",
            "F1-macro final en TEST: 0.8248\n",
            "Validation set reservado para futuros análisis o ensemble\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. COMPARACIÓN TEÓRICA: ¿CUÁNDO GANA CADA MODELO?"
      ],
      "metadata": {
        "id": "rc4Jvof_Dzj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" RESULTADOS FINALES - 6 MODELOS COMPLETOS\")\n",
        "print(\" Métricas: Accuracy | Precision (macro) | Recall (macro) | F1-macro | F1 por clase\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Diccionario para guardar TODAS las métricas\n",
        "full_results = {}\n",
        "\n",
        "# ============================================================\n",
        "# Función para evaluar un modelo y extraer TODAS las métricas\n",
        "# ============================================================\n",
        "\n",
        "def evaluate_model(name, y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, average='macro')\n",
        "    rec = recall_score(y_true, y_pred, average='macro')\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    report = classification_report(y_true, y_pred, output_dict=True)\n",
        "    f1_hate = report['1']['f1-score']\n",
        "    f1_non_hate = report['0']['f1-score']\n",
        "\n",
        "    return {\n",
        "        'Accuracy': acc,\n",
        "        'Precision_macro': prec,\n",
        "        'Recall_macro': rec,\n",
        "        'F1_macro': f1_macro,\n",
        "        'F1_hate': f1_hate,\n",
        "        'F1_non_hate': f1_non_hate\n",
        "    }\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Evaluar todos los modelos guardados en results_A y results_B\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "# Necesitamos volver a predecir con los mejores modelos\n",
        "# (los tenemos en log_grid.best_estimator_, etc.)\n",
        "\n",
        "# --- MODELO A: TF-IDF ---\n",
        "print(\"Evaluando modelos TF-IDF + features...\")\n",
        "# Logistic Regression\n",
        "y_pred = log_grid_A.best_estimator_.predict(X_test_A)\n",
        "full_results['TF-IDF + LogisticRegression'] = evaluate_model('TF-IDF + LR', y_test, y_pred)\n",
        "\n",
        "# Random Forest\n",
        "y_pred = rf_grid_A.best_estimator_.predict(X_test_A)\n",
        "full_results['TF-IDF + RandomForest'] = evaluate_model('TF-IDF + RF', y_test, y_pred)\n",
        "\n",
        "# SVM\n",
        "y_pred = svm_grid_A.best_estimator_.predict(X_test_A)\n",
        "full_results['TF-IDF + SVM'] = evaluate_model('TF-IDF + SVM', y_test, y_pred)\n",
        "\n",
        "# --- MODELO B: GloVe ---\n",
        "print(\"Evaluando modelos GloVe + features...\")\n",
        "\n",
        "# LogisticRegression GloVe\n",
        "best_lr_B = LogisticRegression(**log_grid_B.best_params_, max_iter=1000, class_weight='balanced', random_state=42)\n",
        "best_lr_B.fit(X_train_B, y_train)\n",
        "y_pred_lr_glove = best_lr_B.predict(X_test_B)\n",
        "full_results['GloVe + LogisticRegression'] = evaluate_model('GloVe + LR', y_test, y_pred_lr_glove)\n",
        "\n",
        "# Random Forest GloVe\n",
        "best_rf_B = RandomForestClassifier(**rf_grid_B.best_params_, random_state=42, n_jobs=-1)\n",
        "best_rf_B.fit(X_train_B, y_train)\n",
        "y_pred_rf_glove = best_rf_B.predict(X_test_B)\n",
        "full_results['GloVe + RandomForest'] = evaluate_model('GloVe + RF', y_test, y_pred_rf_glove)\n",
        "\n",
        "# SVM GloVe\n",
        "best_svm_B = LinearSVC(**svm_grid_B.best_params_, class_weight='balanced', max_iter=10000, random_state=42)\n",
        "best_svm_B.fit(X_train_B, y_train)\n",
        "y_pred_svm_glove = best_svm_B.predict(X_test_B)\n",
        "full_results['GloVe + SVM'] = evaluate_model('GloVe + SVM', y_test, y_pred_svm_glove)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Crear tabla bonita con pandas\n",
        "# ------------------------------------------------------------------\n",
        "df_results = pd.DataFrame(full_results).T\n",
        "df_results = df_results.round(4)\n",
        "df_results = df_results.sort_values(by='F1_macro', ascending=False)\n",
        "\n",
        "# Mostrar ranking\n",
        "print(\"\\n\" + \" RANKING FINAL DE MODELOS\")\n",
        "print(\"-\" * 90)\n",
        "print(df_results.to_string())\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Ganador absoluto\n",
        "# ------------------------------------------------------------------\n",
        "winner_name = df_results.index[0]\n",
        "winner_row = df_results.iloc[0]\n",
        "\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(f\" GANADOR ABSOLUTO: {winner_name}\")\n",
        "print(\"=\"*90)\n",
        "print(f\"Accuracy:        {winner_row['Accuracy']:.4f}\")\n",
        "print(f\"Precision (macro): {winner_row['Precision_macro']:.4f}\")\n",
        "print(f\"Recall (macro):    {winner_row['Recall_macro']:.4f}\")\n",
        "print(f\"F1-macro:          {winner_row['F1_macro']:.4f}\")\n",
        "print(f\"F1 (odio):         {winner_row['F1_hate']:.4f}\")\n",
        "print(f\"F1 (no odio):      {winner_row['F1_non_hate']:.4f}\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Classification Report del ganador\n",
        "# ------------------------------------------------------------------\n",
        "winner_model_name = df_results.index[0]\n",
        "\n",
        "if 'TF-IDF' in winner_model_name:\n",
        "    X_test_winner = X_test_A\n",
        "    if 'LogisticRegression' in winner_model_name:\n",
        "        y_pred_winner = log_grid_A.best_estimator_.predict(X_test_winner)\n",
        "    elif 'RandomForest' in winner_model_name:\n",
        "        y_pred_winner = rf_grid_A.best_estimator_.predict(X_test_winner)\n",
        "    elif 'SVM' in winner_model_name:\n",
        "        y_pred_winner = svm_grid_A.best_estimator_.predict(X_test_winner)\n",
        "else: # GloVe model\n",
        "    X_test_winner = X_test_B\n",
        "    if 'LogisticRegression' in winner_model_name:\n",
        "        y_pred_winner = log_grid_B.best_estimator_.predict(X_test_winner)\n",
        "    elif 'RandomForest' in winner_model_name:\n",
        "        y_pred_winner = rf_grid_B.best_estimator_.predict(X_test_winner)\n",
        "    elif 'SVM' in winner_model_name:\n",
        "        y_pred_winner = svm_grid_B.best_estimator_.predict(X_test_winner)\n",
        "\n",
        "print(\"\\nCLASIFICATION REPORT COMPLETO DEL GANADOR:\")\n",
        "print(classification_report(y_test, y_pred_winner, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orpUBfS47X2D",
        "outputId": "97fd65f1-049f-40c0-f37f-ca96d59d5f14"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " RESULTADOS FINALES - 6 MODELOS COMPLETOS\n",
            " Métricas: Accuracy | Precision (macro) | Recall (macro) | F1-macro | F1 por clase\n",
            "================================================================================\n",
            "Evaluando modelos TF-IDF + features...\n",
            "Evaluando modelos GloVe + features...\n",
            "\n",
            " RANKING FINAL DE MODELOS\n",
            "------------------------------------------------------------------------------------------\n",
            "                             Accuracy  Precision_macro  Recall_macro  F1_macro  F1_hate  F1_non_hate\n",
            "GloVe + SVM                    0.8248           0.8248        0.8248    0.8248   0.8238       0.8258\n",
            "GloVe + LogisticRegression     0.8248           0.8248        0.8248    0.8248   0.8248       0.8248\n",
            "TF-IDF + LogisticRegression    0.8095           0.8113        0.8095    0.8092   0.8020       0.8165\n",
            "TF-IDF + SVM                   0.8067           0.8089        0.8067    0.8063   0.7980       0.8146\n",
            "GloVe + RandomForest           0.8010           0.8014        0.8010    0.8009   0.7969       0.8049\n",
            "TF-IDF + RandomForest          0.7590           0.7593        0.7590    0.7590   0.7629       0.7551\n",
            "\n",
            "==========================================================================================\n",
            " GANADOR ABSOLUTO: GloVe + SVM\n",
            "==========================================================================================\n",
            "Accuracy:        0.8248\n",
            "Precision (macro): 0.8248\n",
            "Recall (macro):    0.8248\n",
            "F1-macro:          0.8248\n",
            "F1 (odio):         0.8238\n",
            "F1 (no odio):      0.8258\n",
            "==========================================================================================\n",
            "\n",
            "CLASIFICATION REPORT COMPLETO DEL GANADOR:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8211    0.8305    0.8258       525\n",
            "           1     0.8285    0.8190    0.8238       525\n",
            "\n",
            "    accuracy                         0.8248      1050\n",
            "   macro avg     0.8248    0.8248    0.8248      1050\n",
            "weighted avg     0.8248    0.8248    0.8248      1050\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "REZvzG0Ys-FQ"
      }
    }
  ]
}